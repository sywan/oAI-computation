{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "abb4d226",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"===============================================================================================\n",
    "Overall Asymmetry Index (oAI) computation\n",
    "\n",
    "Reference: \n",
    "1. Shu-Yen Wan, Pei-Ying Tsai, and Lun-Jou Lo, \"Quantifying Perceived Facial Asymmetry to Enhance \n",
    "   Physician-Patient Communications,\" Applied Sciences, vol. 11, no. 18, Pages 8398, 2021. \n",
    "   DOI: 10.3390/app11188398\n",
    "2. R.O.C. (Taiwan) Patent (I595430)\n",
    "\n",
    "Copyright 2022, Shu-Yen Wan, sywan@mail.cgu.edu.tw\n",
    "\n",
    "20 facial landmarks are considered to compute the oAI\n",
    "\n",
    "Estimated facial landmarks - may not be identical with the locations defined by Farkas, L.G. \n",
    "(Anthropometry of the Head and Face; Raven Press: New York, NY, USA, 1994.)\n",
    "\n",
    "01 Glabella (G) => 9\n",
    "    Most prominent midline point between eyebrows\n",
    "02 Nasion (N) => 168\n",
    "    Deepest point of nasal bridge\n",
    "03 Pronasale (Prn) => 4\n",
    "    Most protruded point of the apex nasi\n",
    "04 Subnasale (Sn) => 2\n",
    "    Midpoint of angle at columella base\n",
    "05 Labial Superius (Ls) => 0\n",
    "    Midpoint of the upper vermilion line\n",
    "06 Labial Inferius (Li) => 17\n",
    "    Midpoint of the lower vermilion line\n",
    "07 Stomion (Sto) => 13/14\n",
    "    Midpoint of the mouth orifice\n",
    "08 Menton (Me) => 152\n",
    "    Most inferior point on chin\n",
    "09 Exocanthion (Ex) => 33(r)/263(l)\n",
    "    Outer commissure of the eye fissure \n",
    "10 Endocanthion (En) => 133(r)/362(l)\n",
    "    Inner commissure of the eye fissure\n",
    "11 Alar curvature (Al) => 129(r)/358(l)\n",
    "    Most lateral point on alar contour\n",
    "12 Cheilion (Ch) => 61(r)/291(l)\n",
    "    Point located at lateral labial commissure\n",
    "13 Zygion (Zy) => 116(r)/345(l)\n",
    "    The most lateral extents of the zygomatic arches\n",
    "14 Gonion (Go) => 138(r)/367(l)\n",
    "    The inferior aspect of the mandibe at its most acute point\n",
    "===============================================================================================\"\"\"\n",
    "\n",
    "medial = {\"Glabella\":9, \"Nasion\":168, \"Pronasale\":4, \"Subnasale\":2, \n",
    "          \"Labial Superius\":0, \"Labial Inferius\":17, \"Stomion\":13, \"Menton\":152}\n",
    "bilateral = {\"Exocanthion\":[33,263], \"Endocanthion\":[133,362], \"Alar curvature\":[129,358],\n",
    "            \"Cheilion\":[61,291], \"Zygion\":[116,345], \"Gonion\":[138,367]}\n",
    "\n",
    "weight_medial = [5.09, 5.75, 8.21, 11.11, 4.10, 7.75, 6.38, 8.62]\n",
    "weight_bilateral = [5.13, 5.36, 11.71, 8.76, 5.27, 6.76]\n",
    "\n",
    "weights = weight_medial + weight_bilateral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ee03104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install mediapipe opencv-python\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7b610d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ba50f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling factor\n",
    "scalingFactor = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b1aa8327",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = os.path.join('img')\n",
    "IMAGE_FILES = [f for f in os.listdir(image_path) if os.path.isfile(os.path.join(image_path, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5b040a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: bounding_box()\n",
    "# Description: Determine the bounding box of given landmarks\n",
    "#\n",
    "def bounding_box(landmarks):   # type(landkmakrs): google.protobuf.pyext._message.RepeatedCompositeContainer\n",
    "    if landmarks is None:\n",
    "        print(\"Null landmarks\")\n",
    "        exit()\n",
    "    upper_left = [landmarks[0].x, landmarks[0].y]\n",
    "    bottom_right = [landmarks[0].x, landmarks[0].y]\n",
    "    for point in landmarks:\n",
    "        upper_left[0] = point.x if point.x < upper_left[0] else upper_left[0]\n",
    "        upper_left[1] = point.y if point.y < upper_left[1] else upper_left[1]\n",
    "        bottom_right[0] = point.x if point.x > bottom_right[0] else bottom_right[0]\n",
    "        bottom_right[1] = point.y if point.y > bottom_right[1] else bottom_right[1]\n",
    "    return upper_left, bottom_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "11129e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: create_dataframe\n",
    "# Description: Create dataframe with empty entries\n",
    "# Return: empty dataframe\n",
    "#         header list for feature coordinates\n",
    "#         header list for AI and oAI\n",
    "#\n",
    "def create_dataframe():\n",
    "    #features = ['Image'] \n",
    "    features = []\n",
    "    features2 = []\n",
    "    ai = []\n",
    "    for c in medial.keys():\n",
    "        features.append(c + '.x')\n",
    "        features.append(c + '.y')\n",
    "        features2.append(c)\n",
    "    for c in bilateral.keys():\n",
    "        features.append(c + '_right.x')\n",
    "        features.append(c + '_right.y')\n",
    "        features.append(c + '_left.x')\n",
    "        features.append(c + '_left.y')\n",
    "        features2.append(c)\n",
    "    features2.append('oAI')\n",
    "    return pd.DataFrame(columns=features), pd.DataFrame(columns=features2), features, features2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1149e7d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create an empty dataframe with default header\n",
    "df, df_ai, columns, columns_AIs = create_dataframe()\n",
    "\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    static_image_mode=True,\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5) as face_mesh:\n",
    "    \n",
    "    for idx, file in enumerate(IMAGE_FILES):\n",
    "    \n",
    "        # Load the image and scale to desired size\n",
    "        # All images are stored in os.path.join(image_path, file)\n",
    "        annotated_image = cv2.imread(os.path.join(image_path,file))\n",
    "        width = int(annotated_image.shape[1]*scalingFactor)\n",
    "        height = int(annotated_image.shape[0]*scalingFactor)\n",
    "        annotated_image = cv2.resize(annotated_image, (width, height), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        # Convert the BGR image to RGB before processing.\n",
    "        results = face_mesh.process(cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        # Compile the dataframe data for each row\n",
    "        # coord: feature coordinates\n",
    "        # AIs: AI and oAI\n",
    "        coord = []\n",
    "        AIs = []\n",
    "        \n",
    "        # Print and draw face mesh landmarks on the image.\n",
    "        if not results.multi_face_landmarks:\n",
    "            continue\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "      \n",
    "            # Determine the bounding box and de-normalize\n",
    "            upper_left, bottom_right = bounding_box(face_landmarks.landmark)\n",
    "            upper_left[0] = int(upper_left[0]*width)\n",
    "            upper_left[1] = int(upper_left[1]*height)\n",
    "            bottom_right[0] = int(bottom_right[0]*width)\n",
    "            bottom_right[1] = int(bottom_right[1]*height)\n",
    "            cv2.rectangle(annotated_image, upper_left, bottom_right, color=(0,0,255), thickness=2)\n",
    "            \n",
    "            # Exocanthion(right,left) and Nasion are explicitly extracted to perform pre-computation\n",
    "            Exocanthion_right = face_landmarks.landmark[bilateral['Exocanthion'][0]]\n",
    "            Exocanthion_left = face_landmarks.landmark[bilateral['Exocanthion'][1]]\n",
    "            Nasion = face_landmarks.landmark[medial['Nasion']]\n",
    "            Ex_r_x = int(face_landmarks.landmark[bilateral['Exocanthion'][0]].x*width)\n",
    "            Ex_r_y = int(face_landmarks.landmark[bilateral['Exocanthion'][0]].y*height)\n",
    "            Ex_l_x = int(face_landmarks.landmark[bilateral['Exocanthion'][1]].x*width)\n",
    "            Ex_l_y = int(face_landmarks.landmark[bilateral['Exocanthion'][1]].y*height)\n",
    "            N_x = int(face_landmarks.landmark[medial['Nasion']].x*width)\n",
    "            N_y = int(face_landmarks.landmark[medial['Nasion']].y*height)\n",
    "            \n",
    "            \"\"\"\n",
    "            medial = {\"Glabella\":9, \"Nasion\":168, \"Pronasale\":4, \"Subnasale\":2, \n",
    "                      \"Labial Superius\":0, \"Labial Inferius\":17, \"Stomion\":13, \"Menton\":152}\n",
    "            bilateral = {\"Exocanthion\":[33,263], \"Endocanthion\":[133,362], \"Alar curvature\":[129,358],\n",
    "                        \"Cheilion\":[61,291], \"Zygion\":[116,345], \"Gonion\":[138,367]}\n",
    "            \"\"\"\n",
    "          \n",
    "            # slope (Sagittal normal) = (Ex_left.y-Ex_right.y)/(Ex_left.x-Ex_right.x)\n",
    "            # constant_term = (N.x+(slope)*N.y)\n",
    "            slope = float(Ex_l_y-Ex_r_y)/float(Ex_l_x-Ex_r_x)\n",
    "            sqrt_slope_square_plus_1 = math.sqrt(slope**2+1)\n",
    "            constant_term = N_x+(slope)*N_y\n",
    "                \n",
    "            for id in medial.keys():\n",
    "                point = face_landmarks.landmark[medial[id]]\n",
    "                x = int(point.x * width)\n",
    "                y = int(point.y * height) \n",
    "                z = int(point.z * width)\n",
    "                coord.append(x)\n",
    "                coord.append(y)\n",
    "                ai = round(abs(x+(slope)*y-constant_term)/sqrt_slope_square_plus_1,2)\n",
    "                AIs.append(ai)\n",
    "                \n",
    "                #print(\"{} ({},{},{})\".format(id, x, y, z))\n",
    "                cv2.circle(annotated_image, (x,y), radius=2, thickness=3, color=(255,0,255))\n",
    "            for id in bilateral.keys():\n",
    "                point_r = face_landmarks.landmark[bilateral[id][0]]\n",
    "                point_l = face_landmarks.landmark[bilateral[id][1]]\n",
    "                x_right = int(point_r.x * width)\n",
    "                y_right = int(point_r.y * height) \n",
    "                z_right = int(point_r.z * width) \n",
    "                x_left = int(point_l.x * width)\n",
    "                y_left = int(point_l.y * height) \n",
    "                z_left = int(point_l.z * width) \n",
    "                coord.append(x_right)\n",
    "                coord.append(y_right)\n",
    "                coord.append(x_left)\n",
    "                coord.append(y_left)\n",
    "                #print(\"{}_right ({},{},{})\".format(id, x_right, y_right, z_right))\n",
    "                #print(\"{}_left ({},{},{})\".format(id, x_left, y_left, z_left))\n",
    "                ai_1 = abs(x_right+(slope)*y_right-constant_term) - abs(x_left+(slope)*y_left-constant_term)\n",
    "                ai_2 = abs(slope*(x_left-x_right)-(y_left-y_right))/sqrt_slope_square_plus_1\n",
    "                ai = round(math.sqrt(pow(ai_1/2,2)+pow(ai_2,2)),2)\n",
    "                AIs.append(ai)\n",
    "                cv2.circle(annotated_image, (x_right,y_right), radius=2, thickness=3, color=(255,0,0))\n",
    "                cv2.circle(annotated_image, (x_left,y_left), radius=2, thickness=3, color=(255,0,0))\n",
    "                \n",
    "            df_temp = pd.DataFrame([coord], columns=columns, index=[file])\n",
    "            df = pd.concat([df, df_temp])\n",
    "            \n",
    "            oai = 0.0\n",
    "            for i in range(len(AIs)):\n",
    "                oai += AIs[i]*weights[i]\n",
    "            AIs.append(round(oai/100,2))\n",
    "            df_temp = pd.DataFrame([AIs], columns=columns_AIs, index=[file])\n",
    "            df_ai = pd.concat([df_ai, df_temp])\n",
    "\n",
    "        if not os.path.exists('tmp'): os.mkdir('tmp')\n",
    "        cv2.imwrite('tmp/annotated_' + file.split('.')[0] + '.png', annotated_image)\n",
    "\n",
    "# Export to an Excel file with multiple DataFrames\n",
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "# Write each dataframe to a different worksheet.\n",
    "# Close the Pandas Excel writer and output the Excel file.\n",
    "writer = pd.ExcelWriter(\"oAI_computation.xlsx\", engine=\"xlsxwriter\")\n",
    "df.to_excel(writer, sheet_name=\"Features\")\n",
    "df_ai.to_excel(writer, sheet_name=\"AIs+oAI\")\n",
    "writer.save()\n",
    "\n",
    "#***** Display the final annotated ouput, just for demonstration!! *****\n",
    "winName = \"Face Mesh\"\n",
    "cv2.namedWindow(winName, cv2.WINDOW_AUTOSIZE)\n",
    "cv2.imshow(winName, annotated_image)\n",
    "\n",
    "while cv2.waitKey(0) & 0xFF not in [27, ord('q'), ord('Q')]:\n",
    "    pass\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "#***** Display annotated ouput *****"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
